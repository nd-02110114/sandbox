{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6章 学習に関するテクニック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 誤差逆伝播法と数値微分の計算量の違い\n",
    "\n",
    "> 確かに数値微分はパラメータ毎の勾配を求めるためにはネットワーク全体を2回順伝播することになるのに対して、誤差逆伝播法の場合は順伝播と逆伝播の合計 2 回だけで演算終わるもんなー。なので、数値微分自体の計算が重いというよりは、数値微分の場合はレイヤ数に比例して計算量が増えるので重いと言った方が適切なんだろうな。\n",
    "\n",
    "数値微分は、確かに各パラメータの損失関数に対する微分を算出する際に、２回分損失関数の出力を必要とするため(f(x+h), f(x-h))  \n",
    "単純に順伝播を２回していることになる  => 計算量的には、`パラメータ × 順伝播2回`\n",
    "\n",
    "一方で誤差逆伝播法は、順伝播, 逆伝播の２回で終了する\n",
    "\n",
    "すなわち、パラメータの個数分、すなわち層の個数分に比例して、計算量は大きくなると考えられる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重みの値\n",
    "\n",
    "重みは均等になると、学習ができなくなる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.11236666666666667 , 0.1135\n",
      "train acc, test acc | 0.13686666666666666 , 0.1399\n",
      "train acc, test acc | 0.2903833333333333 , 0.2915\n",
      "train acc, test acc | 0.3122 , 0.3124\n",
      "train acc, test acc | 0.3458 , 0.3486\n",
      "train acc, test acc | 0.34868333333333335 , 0.351\n",
      "train acc, test acc | 0.34605 , 0.3404\n",
      "train acc, test acc | 0.38356666666666667 , 0.3763\n",
      "train acc, test acc | 0.49648333333333333 , 0.4916\n",
      "train acc, test acc | 0.5725 , 0.5681\n",
      "train acc, test acc | 0.66765 , 0.6606\n",
      "train acc, test acc | 0.7544166666666666 , 0.754\n",
      "train acc, test acc | 0.7919666666666667 , 0.7936\n",
      "train acc, test acc | 0.8025833333333333 , 0.8086\n",
      "train acc, test acc | 0.8167833333333333 , 0.8202\n",
      "train acc, test acc | 0.8251 , 0.8288\n",
      "train acc, test acc | 0.8292333333333334 , 0.8351\n"
     ]
    }
   ],
   "source": [
    "# バッチ\n",
    "# エポック・・・学習の単位\n",
    " \n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "# 重みを0にした\n",
    "from sample.two_layer_net_weight_zero import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "         load_mnist(normalize=True, one_hot_label=True)\n",
    "    \n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "#  ハイパーパラメータ\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "# １エポックあたりの繰り返し数\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # ミニバッチの取得\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配の計算\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # パラメータの更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 学習経過の記録\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \" , \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**重み０ではない時**\n",
    "\n",
    "train acc, test acc | 0.0987166666667 , 0.098  \n",
    "train acc, test acc | 0.787033333333 , 0.7893  \n",
    "train acc, test acc | 0.878083333333 , 0.8841  \n",
    "train acc, test acc | 0.900033333333 , 0.9034  \n",
    "train acc, test acc | 0.909316666667 , 0.9142  \n",
    "train acc, test acc | 0.915766666667 , 0.9188  \n",
    "train acc, test acc | 0.921466666667 , 0.9227  \n",
    "train acc, test acc | 0.924983333333 , 0.9265  \n",
    "train acc, test acc | 0.928783333333 , 0.9313  \n",
    "train acc, test acc | 0.9324 , 0.9328  \n",
    "train acc, test acc | 0.93515 , 0.9361  \n",
    "train acc, test acc | 0.937483333333 , 0.9387  \n",
    "train acc, test acc | 0.939766666667 , 0.9405  \n",
    "train acc, test acc | 0.942516666667 , 0.9425  \n",
    "train acc, test acc | 0.944966666667 , 0.9435  \n",
    "train acc, test acc | 0.946833333333 , 0.9451  \n",
    "train acc, test acc | 0.948216666667 , 0.947  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 パラメータの更新方法\n",
    "* SGD : 確率的勾配降下法・・・・勾配を使って、勾配方向にパラメータを更新する\n",
    "* Momentum・・・・重みパラメータに、速度などの概念を導入する\n",
    "* AdaGrad・・・・パラメータの要素ごとに適応的に学習係数を調整しながら学習を行う手法\n",
    "* Adam・・・・AdaGrad + Momenutmって感じ、難しいから詳細は論文参考\n",
    "\n",
    "現在は, `SGD or Adam`って感じ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 重みの初期値\n",
    "\n",
    "*活性化関数の後の出力データの分布が適切に広がっていると、学習が早く正確に進む*\n",
    "\n",
    "* 重みの初期値は、均一な値 or 小さすぎる値になってはいけない => **勾配損失**によって学習が進まなくなるから\n",
    "\n",
    "活性化関数が線形である時\n",
    "* Xavier の初期値 : $ \\frac{1}{\\sqrt{n}}$ の標準偏差を持つガウス分布で初期化\n",
    "\n",
    "Reluの場合の時\n",
    "* Heの初期値 : $ \\sqrt{\\frac{2}{n}}$の標準偏差を持つガウス分布で初期化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Batch Normalization\n",
    "\n",
    "各レイヤの間に、アクティベーション(活性化関数の後の出力データ)の分布を適度に設定する処理を挟むこと  \n",
    "具体的には、\n",
    "1. データの分布が平均が 0で分散が 1 になるように正規化を行う  \n",
    "2. この正規化されたデータに対して、固有のスケー ルとシフトで変換を行う (ここでのスケール、シフトの大きさは学習によって最適な値をセット)\n",
    "\n",
    "**利点**\n",
    "* 学習時間の短縮\n",
    "* 初期値の依存性を減らす = 「初期値にロバスト」\n",
    "* 過学習の抑制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 正則化\n",
    "**過学習の原因**\n",
    "* パラメータを大量に持ち、表現力の高いモデルであること\n",
    "* 訓練データが少ないこと\n",
    "\n",
    "・・・訓練データとテストデータの乖離が大きいと時が一般に過学習と呼ばれる\n",
    "\n",
    "**対策**\n",
    "* Weight Decay\n",
    "  * 重みを W とすれば、L2 ノルムの Weight decay は、$\\frac{1}{2} \\lambda W^{2}$ になり、これを損失関数に加算します。  \n",
    "    ここで、λ は正則化の強さをコントロールするハイパーパラメーター\n",
    "  * > 一般的にoverfitを防ぐための常套手段は、「何がoverfitっぽいか」ということを数値化してそれを損失関数に加えること 今回は、「一部の係数だけやたらデカい」=> 「Wがデカい」とoverfitっぽい、と考えているからL2ノルムを設定した。\n",
    "\n",
    "* Dropout\n",
    "  * ニューロンをランダムに消去しながら学習する手法\n",
    "  \n",
    "**アンサンブル学習**\n",
    "> 機械学習では、アンサンブル学習というものをよく使います。アンサンブル学習とは、複数のモデルを個別に学習させ、推論時には、その複数の出力を平均するというものです。ニューラルネットワークの文脈で話をすると、たとえば、 5つの同じ構造(もしくは似た構造)のネットワークを用意して、それぞれに学習させ、テストのときには、その5つの出力の平均を答えとします。アンサ ンブル学習を行うことで、ニューラルネットワークの認識精度が数 % 向上する ことが実験的に分かっています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 ハイパーパラメータの検証\n",
    "\n",
    "**ハイパーパラメータの種類**\n",
    "* 各層のニューロンの数\n",
    "* バッチサイズ\n",
    "* パラメーター更新の学習係数\n",
    "* Weight Decay\n",
    "\n",
    "\n",
    "これらを決定するために、訓練データやテストデータとは別に`検証データ`というものを用意する\n",
    "\n",
    "**ハイパーパラメーターの決定法**  \n",
    "・・・・*基本的には、ランダムサンプリングによる探索*\n",
    "\n",
    "1. ハイパーパラメータの範囲を設定する\n",
    "2. 設定されたハイパーパラメータの範囲から、ランダムにサンプリングする\n",
    "3. ステップ 1 でサンプリングされたハイパーパラメータの値を使用して学習を行い、検証データで認識精度を評価する(ただし、エポックは小さく設定)。\n",
    "4. ステップ 1 とステップ 2 をある回数(100 回など)繰り返し、それらの認識精 度の結果から、ハイパーパラメータの範囲を狭める。\n",
    "\n",
    "以上で、決定した範囲からハイパーパラメータを一つ選択して学習する  \n",
    "また、ハイパーパラメー タの最適化において、より洗練された手法を求めるとすれば、`ベイズ最適化`などがある\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
